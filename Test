–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—Ç–æ—Ä–æ–≥–æ —ç—Ç–∞–ø–∞ (–∞–Ω–∞–ª–∏–∑ –∏ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö)

üìÇ data_analysis_project/
‚îú‚îÄ‚îÄ config.py ‚Üí –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
‚îú‚îÄ‚îÄ scraper.py ‚Üí –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å Reddit, Facebook –∏ –¥—Ä—É–≥–∏—Ö –ø–ª–æ—â–∞–¥–æ–∫
‚îú‚îÄ‚îÄ analyzer.py ‚Üí –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ —É—Ç–µ—á–µ–∫
‚îú‚îÄ‚îÄ telegram_bot.py ‚Üí –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram
‚îú‚îÄ‚îÄ logger.py ‚Üí –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–∫—Ä–∏–ø—Ç–æ–≤
‚îî‚îÄ‚îÄ main.py ‚Üí –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞


---

1. config.py ‚Äì –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

# –ü—É—Ç–∏
DATA_DIR = "./collected_data"  # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
LOG_FILE = "./data_analysis.log"  # –§–∞–π–ª –ª–æ–≥–æ–≤

# Telegram-–±–æ—Ç
TELEGRAM_BOT_TOKEN = "YOUR_BOT_TOKEN"
TELEGRAM_CHAT_ID = "YOUR_CHAT_ID"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
SCRAPER_SOURCES = ["reddit", "facebook"]
REDDIT_SUBS = ["onlyfansadvice", "onlyfansmarketing"]
FACEBOOK_GROUPS = ["onlyfans-promotion", "onlyfans-secrets"]

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞
TREND_THRESHOLD = 5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
LEAK_KEYWORDS = ["leak", "exposed", "password dump"]


---

2. scraper.py ‚Äì —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö

import os
import json
import requests
import config
from datetime import datetime
import logger

def scrape_reddit():
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å–∞–±—Ä–µ–¥–¥–∏—Ç–æ–≤.
    """
    collected_posts = []
    headers = {"User-Agent": "Mozilla/5.0"}

    for subreddit in config.REDDIT_SUBS:
        url = f"https://www.reddit.com/r/{subreddit}/new.json?limit=100"
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            posts = response.json()["data"]["children"]
            for post in posts:
                collected_posts.append({
                    "platform": "Reddit",
                    "source": subreddit,
                    "title": post["data"]["title"],
                    "text": post["data"].get("selftext", ""),
                    "url": post["data"]["url"],
                    "timestamp": datetime.utcnow().isoformat()
                })

    save_data(collected_posts, "reddit.json")
    return collected_posts

def scrape_facebook():
    """
    –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å Facebook.
    """
    collected_posts = [
        {"platform": "Facebook", "source": "onlyfans-promotion", "title": "Example Post", "text": "Promo tips", "url": "http://facebook.com/post", "timestamp": datetime.utcnow().isoformat()}
    ]
    save_data(collected_posts, "facebook.json")
    return collected_posts

def save_data(data, filename):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª.
    """
    os.makedirs(config.DATA_DIR, exist_ok=True)
    file_path = os.path.join(config.DATA_DIR, filename)
    
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4)
    
    logger.log_event(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")

def run_scrapers():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Å–±–æ—Ä—â–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    all_data = []
    if "reddit" in config.SCRAPER_SOURCES:
        all_data.extend(scrape_reddit())
    if "facebook" in config.SCRAPER_SOURCES:
        all_data.extend(scrape_facebook())

    return all_data


---

3. analyzer.py ‚Äì –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö

import json
import os
import config
import logger

def analyze_trends():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """
    trends = {}
    for file in os.listdir(config.DATA_DIR):
        with open(os.path.join(config.DATA_DIR, file), "r", encoding="utf-8") as f:
            posts = json.load(f)
            for post in posts:
                words = post["text"].split()
                for word in words:
                    trends[word] = trends.get(word, 0) + 1

    top_trends = {k: v for k, v in trends.items() if v >= config.TREND_THRESHOLD}
    logger.log_event(f"–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã: {top_trends}")
    return top_trends

def detect_leaks():
    """
    –ò—â–µ—Ç —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    leaks = []
    for file in os.listdir(config.DATA_DIR):
        with open(os.path.join(config.DATA_DIR, file), "r", encoding="utf-8") as f:
            posts = json.load(f)
            for post in posts:
                if any(keyword in post["text"].lower() for keyword in config.LEAK_KEYWORDS):
                    leaks.append(post)

    logger.log_event(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É—Ç–µ—á–µ–∫: {len(leaks)}")
    return leaks


---

4. telegram_bot.py ‚Äì –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

import requests
import config
import logger

def send_telegram_message(text):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram.
    """
    url = f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}/sendMessage"
    data = {"chat_id": config.TELEGRAM_CHAT_ID, "text": text}

    response = requests.post(url, data=data)
    if response.status_code == 200:
        logger.log_event("–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
    else:
        logger.log_event("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram")


---

5. logger.py ‚Äì –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

import config
from datetime import datetime

def log_event(message):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –ª–æ–≥.
    """
    timestamp = datetime.utcnow().isoformat()
    log_entry = f"[{timestamp}] {message}\n"

    with open(config.LOG_FILE, "a") as f:
        f.write(log_entry)

    print(log_entry.strip())


---

6. main.py ‚Äì –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞

import scraper
import analyzer
import telegram_bot

def main():
    print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö...")
    data = scraper.run_scrapers()

    print("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã...")
    trends = analyzer.analyze_trends()
    if trends:
        telegram_bot.send_telegram_message(f"üî• –ù–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã: {trends}")

    print("‚ö†Ô∏è –ò—â–µ–º —É—Ç–µ—á–∫–∏...")
    leaks = analyzer.detect_leaks()
    if leaks:
        telegram_bot.send_telegram_message(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.")

if __name__ == "__main__":
    main()


---

–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?

1Ô∏è‚É£ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

python -m venv venv  
source venv/bin/activate  # (Linux/macOS)  
venv\Scripts\activate  # (Windows)  
pip install requests

2Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å config.py
üîπ –£–∫–∞–∑–∞—Ç—å Telegram-—Ç–æ–∫–µ–Ω –∏ chat_id
üîπ –î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–∏ —Å–∞–±—Ä–µ–¥–¥–∏—Ç—ã, Facebook-–≥—Ä—É–ø–ø—ã

3Ô∏è‚É£ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑

python main.py


---

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å

‚úÖ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å Reddit –∏ Facebook.
‚úÖ –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ (–ø–æ–∏—Å–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º).
‚úÖ –ü–æ–∏—Å–∫ —É—Ç–µ—á–µ–∫ (—Å–ª–æ–≤–∞ "leak", "password dump" –∏ —Ç. –¥.).
‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram –æ –Ω–æ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–∞—Ö –∏ —É—Ç–µ—á–∫–∞—Ö.
‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.

–ö–∞–∫ —Ç–µ–±–µ —ç—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç? –ù—É–∂–Ω–æ –ª–∏ —á—Ç–æ-—Ç–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å?
